
My notes and project notes on AI Research.

## ML Research Flow:

(daily like 1hr to each topics will help to get a foot in the door)

- Maths:
    1. Why Machines Learn → Anil Anathaswamy (in the context of Machine Learning)
    2. Khan Academy for doubts and quick revision
- ML:
    - Classical Machine Learning is not the most flashy thing we use today
    - Andrew Ng’s ML Learning Specialisation → Practical exercises on building machine learning examples and builds basic ML pipelines.
- DL:
    - Do you want to learn deep learning to a level where you can understand the current machine learning techniques and models and apply them to a certain problems.
        - Applied path to get a job faster.
        - Andrew Ng’s Deep Learning Specialization (does not cover transformer architecture)
        - Stanford CS25 Lectures. + Andrej Karpathy’s Lectures.
    - Do you really wanna learn Deep Learning ? Theory + new models(KAN networks)
        - Understanding Deep Learning (ton of content about deep learning and every relevant model that we need to know)
        - This is actually a free resource online.
        - Has a lot of theoretical and practical exercises.
        - Puts more emphasis on the Transformer architecture.
- Projects:
    - ML Projects → numpy, pandas and matplotlib for manipulating and visualizing data. even a 20min tutorial is enough.
    - See a PyTorch tutorial online , really start with Kaggle and solve the problems and go through the lectures possible and if we continue to progressing on more and more advanced challenges.
    - Reimplementing a paper is basically the best project. Learn a ton.
        - Pick a paper suited to our level and go through it.
        - Read paper alone and look at code to understand how to improve our own codebase.